<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://cdn.jsdelivr.net/npm/protobufjs@7.X.X/dist/protobuf.min.js"></script>
    <title>Chat - Kreesalis Assistant</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Poppins', sans-serif;
            text-align: center;
            background: linear-gradient(135deg, #a5c9f0, #67acf7);
            color: white;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            position: relative;
        }
        
        .top-bar {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            background: rgba(0, 0, 0, 0.2);
            display: flex;
            align-items: center;
            justify-content: space-between;
            padding: 15px 30px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.2);
        }

        .logo {
            height: 40px;
        }

        .back-btn {
            background: #ffffff30;
            color: white;
            font-size: 14px;
            padding: 8px 16px;
            border-radius: 20px;
            margin-right: 2%;
            border: none;
            cursor: pointer;
            transition: all 0.3s ease-in-out;
        }

        .back-btn:hover {
            background: rgba(255, 255, 255, 0.5);
            color: black;
        }

        .container {
            background: rgba(255, 255, 255, 0.1);
            padding: 40px;
            border-radius: 15px;
            backdrop-filter: blur(10px);
            box-shadow: 0 4px 10px rgba(0, 0, 0, 0.2);
            max-width: 400px;
            margin-top: 70px;
        }

        h1 {
            font-size: 28px;
            margin-bottom: 10px;
        }

        .chat-box {
            text-align: left;
            max-height: 250px;
            overflow-y: auto;
            background: rgba(255,255,255,0.2);
            padding: 10px;
            border-radius: 10px;
            margin-bottom: 15px;
        }

        .message {
            padding: 5px;
            border-radius: 8px;
            margin-bottom: 5px;
        }

        .user-message {
            color: #f4f4f4;
            text-align: right;
        }

        .bot-message {
            color: #ffcccb;
            text-align: left;
        }

        .btn {
            background: #ff6b6b;
            color: white;
            border: none;
            padding: 12px 24px;
            font-size: 18px;
            border-radius: 25px;
            cursor: pointer;
            transition: all 0.3s ease-in-out;
            margin: 10px;
        }

        .btn:hover {
            background: #ff4757;
            transform: scale(1.1);
        }
    </style>
</head>
<body>

    <div class="top-bar">
        <img src="./meida/kreesalis_white_text.png" alt="Kreesalis Logo" class="logo">
        <button class="back-btn" onclick="location.href='index.html'">Back to Home</button>
    </div>

    <div class="container">
        <h1>Kreesalis Voice Assistant</h1>
        <h3><div id="progressText">Loading, please wait...</div></h3>
        <button id="startAudioBtn" class="btn">Start Audio</button>
        <button id="stopAudioBtn" class="btn">Stop Audio</button>
    </div>

    <script>
        const SAMPLE_RATE = 16000;
        const NUM_CHANNELS = 1;
        const PLAY_TIME_RESET_THRESHOLD_MS = 1.0;
  
        // The protobuf type. We will load it later.
        let Frame = null;
  
        // The websocket connection.
        let ws = null;
  
        // The audio context
        let audioContext = null;
  
        // The audio context media stream source
        let source = null;
  
        // The microphone stream from getUserMedia. SHould be sampled to the
        // proper sample rate.
        let microphoneStream = null;
  
        // Script processor to get data from microphone.
        let scriptProcessor = null;
  
        // AudioContext play time.
        let playTime = 0;
  
        // Last time we received a websocket message.
        let lastMessageTime = 0;
  
        // Whether we should be playing audio.
        let isPlaying = false;
  
        let startBtn = document.getElementById('startAudioBtn');
        let stopBtn = document.getElementById('stopAudioBtn');
  
        const proto = protobuf.load('frames.proto', (err, root) => {
            if (err) {
                throw err;
            }
            Frame = root.lookupType('pipecat.Frame');
            const progressText = document.getElementById('progressText');
            progressText.textContent = 'We are ready! Make sure to run the server and then click `Start Audio`.';
  
            startBtn.disabled = false;
            stopBtn.disabled = true;
        });
  
        function initWebSocket() {
            ws = new WebSocket('ws://localhost:8765');
            // This is so `event.data` is already an ArrayBuffer.
            ws.binaryType = 'arraybuffer';
  
            ws.addEventListener('open', handleWebSocketOpen);
            ws.addEventListener('message', handleWebSocketMessage);
            ws.addEventListener('close', (event) => {
                console.log('WebSocket connection closed.', event.code, event.reason);
                stopAudio(false);
            });
            ws.addEventListener('error', (event) => console.error('WebSocket error:', event));
        }
  
        function handleWebSocketOpen(event) {
          console.log('WebSocket connection established.', event)
  
          navigator.mediaDevices.getUserMedia({
                audio: {
                    sampleRate: SAMPLE_RATE,
                    channelCount: NUM_CHANNELS,
                    autoGainControl: true,
                    echoCancellation: true,
                    noiseSuppression: true,
                }
            }).then((stream) => {
                microphoneStream = stream;
                // 512 is closest thing to 200ms.
                scriptProcessor = audioContext.createScriptProcessor(512, 1, 1);
                source = audioContext.createMediaStreamSource(stream);
                source.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
  
                scriptProcessor.onaudioprocess = (event) => {
                    if (!ws) {
                        return;
                    }
  
                    const audioData = event.inputBuffer.getChannelData(0);
                    const pcmS16Array = convertFloat32ToS16PCM(audioData);
                    const pcmByteArray = new Uint8Array(pcmS16Array.buffer);
                    const frame = Frame.create({
                        audio: {
                            audio: Array.from(pcmByteArray),
                            sampleRate: SAMPLE_RATE,
                            numChannels: NUM_CHANNELS
                        }
                    });
                    const encodedFrame = new Uint8Array(Frame.encode(frame).finish());
                    ws.send(encodedFrame);
                };
            }).catch((error) => console.error('Error accessing microphone:', error));
        }
  
        function handleWebSocketMessage(event) {
            const arrayBuffer = event.data;
            if (isPlaying) {
                enqueueAudioFromProto(arrayBuffer);
            }
        }
  
        function enqueueAudioFromProto(arrayBuffer) {
            const parsedFrame = Frame.decode(new Uint8Array(arrayBuffer));
            if (!parsedFrame?.audio) {
                return false;
            }
  
            // Reset play time if it's been a while we haven't played anything.
            const diffTime = audioContext.currentTime - lastMessageTime;
            if ((playTime == 0) || (diffTime > PLAY_TIME_RESET_THRESHOLD_MS)) {
                playTime = audioContext.currentTime;
            }
            lastMessageTime = audioContext.currentTime;
  
            // We should be able to use parsedFrame.audio.audio.buffer but for
            // some reason that contains all the bytes from the protobuf message.
            const audioVector = Array.from(parsedFrame.audio.audio);
            const audioArray = new Uint8Array(audioVector);
  
            audioContext.decodeAudioData(audioArray.buffer, function(buffer) {
                const source = new AudioBufferSourceNode(audioContext);
                source.buffer = buffer;
                source.start(playTime);
                source.connect(audioContext.destination);
                playTime = playTime + buffer.duration;
            });
        }
  
        function convertFloat32ToS16PCM(float32Array) {
            let int16Array = new Int16Array(float32Array.length);
  
            for (let i = 0; i < float32Array.length; i++) {
                let clampedValue = Math.max(-1, Math.min(1, float32Array[i]));
                int16Array[i] = clampedValue < 0 ? clampedValue * 32768 : clampedValue * 32767;
            }
            return int16Array;
        }
  
        function startAudioBtnHandler() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                alert('getUserMedia is not supported in your browser.');
                return;
            }
  
            startBtn.disabled = true;
            stopBtn.disabled = false;
  
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
                latencyHint: 'interactive',
                sampleRate: SAMPLE_RATE
            });
  
            isPlaying = true;
  
            initWebSocket();
        }
  
        function stopAudio(closeWebsocket) {
            playTime = 0;
            isPlaying = false;
            startBtn.disabled = false;
            stopBtn.disabled = true;
  
            if (ws && closeWebsocket) {
                ws.close();
                ws = null;
            }
  
            if (scriptProcessor) {
                scriptProcessor.disconnect();
            }
            if (source) {
                source.disconnect();
            }
        }
  
        function stopAudioBtnHandler() {
            stopAudio(true);
        }
  
        startBtn.addEventListener('click', startAudioBtnHandler);
        stopBtn.addEventListener('click', stopAudioBtnHandler);
        startBtn.disabled = true;
        stopBtn.disabled = true;
      </script>

</body>
</html>
